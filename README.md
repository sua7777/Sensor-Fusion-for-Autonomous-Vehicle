# Seosor Fusion for Autonomous Vehicle using Lidar and Camera Sensors

This project aims to combine data from two sensors, cameras (2D) and LiDAR(3D), into a real time obstacle tracking and classication model for AVs. This is based on data collected from cars fitted with cameras and Velodyne LiDAR systems, and the config files for the setup are included in this repo.


What about the data?

The data here comes from RGB cameras mounted on the car (images), as well as a LiDAR system fitted on the top that outputs point clouds. You can find the files in the data folder, separated into images & points.


What's the idea behind this?

As autonomous vehicles become more mainstream, it's fun to see how they perceive the world around them. Here's a typical setup in a rig like such:

![687474703a2f2f7777772e63766c6962732e6e65742f64617461736574732f6b697474692f696d616765732f7061737361745f73656e736f72732e6a7067](https://github.com/user-attachments/assets/d447f8db-73cc-46e8-b143-68154dd55dca)

